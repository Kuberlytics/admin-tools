{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kubernetes on Azure\n",
    "\n",
    "This notebook can be used to launch a Kubernetes Cluster on the [Azure](https://portal.azure.com). \n",
    "\n",
    "1. First make sure that [Azure CLI and kubectl are  installed on your computer](https://github.com/Azure/azure-cli).\n",
    "2. Install kubectl. \n",
    "`az acs kubernetes install-cli`\n",
    "2. Make sure [helm is installed](https://zero-to-jupyterhub-with-kubernetes.readthedocs.io/en/latest/setup-helm.html).\n",
    "\n",
    "\n",
    "How big of a cluster do you need? Check out [this spreadsheet](https://docs.google.com/spreadsheets/d/1EvGMgS2JiGm8UuB9eDOQRjm79LapjJz4ubk7YDVqplY/edit?usp=sharing) or this \n",
    "[Notebook](https://github.com/data-8/jupyterhub-k8s/blob/master/docs/cost-estimation/gce_budgeting.ipynb) to estimate the size. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration Setup\n",
    "\n",
    "The general configuration is in `/config/azure`.\n",
    "\n",
    "\n",
    "\n",
    "### Cluster Properties\n",
    "*Resource Group (resource_group)*:  This will help with tracking costs and deleting things. \n",
    "\n",
    "*Locations* \n",
    "\n",
    "*Namesapece*: You can read more about namespaces [here](https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/).\n",
    "\n",
    "*Releasename*: A releasename is a way of versioning your system.  \n",
    "\n",
    "*Zone*: See this advice from google on [choosing a zone](https://cloud.google.com/compute/docs/regions-zones/regions-zones#choosing_a_region_and_zone).\n",
    "\n",
    "### Cluster Size and Autoscaling\n",
    "\n",
    "*Number of Nodes (num_nodes)*: This is the number of servers which you are asking Google to launch.  This will clearly be one of the factors which drives the overall costs.\n",
    "\n",
    "*Machine Type*: This is a (https://cloud.google.com/compute/docs/machine-types)\n",
    "\n",
    "*Maximum Number of Nodes (max_nodes)*: If you enable autoscaling, Google will launch additional servers based on demand, up to the `maz Autoscaling is the process of increasing the number of servers based on demand.\n",
    "\n",
    "**If you would like to make changes, just update the Kubernetes.yaml file.** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import ruamel.yaml \n",
    "#This is your configuration file. \n",
    "general_yaml='../../config/config.yaml'\n",
    "with open(general_yaml, 'r') as yaml:\n",
    "    cf=ruamel.yaml.round_trip_load(yaml, preserve_quotes=True)\n",
    "\n",
    "#This will import some required libraries.\n",
    "\n",
    "azure_yaml='../../config/azure/config_tst.yaml'\n",
    "#azure_yaml='../../config/azure/config_prd.yaml'\n",
    "with open(azure_yaml, 'r') as a_yaml:\n",
    "    cf_a=ruamel.yaml.round_trip_load(a_yaml, preserve_quotes=True)\n",
    "\n",
    "if cf['docker']:\n",
    "    cf_a['path']=cf['docker_path']\n",
    "else:\n",
    "    cf_a['path']=cf['local_path']\n",
    "\n",
    "sys.path.append(cf_a['path']+\"/lib/kuberutils\") \n",
    "print(cf_a['path']+\"/lib/kuberutils\")\n",
    "import importlib\n",
    "import kuberutils as ku\n",
    "importlib.reload(ku)\n",
    "#This will load common commands for your cluster\n",
    "cf_a=ku.azure_commands(cf_a)\n",
    "print(ruamel.yaml.dump(cf_a, sys.stdout, Dumper=ruamel.yaml.RoundTripDumper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Login\n",
    "\n",
    "In order to use the web login, you need to run the command below and then enter the code in the generated we link.  Careful not to commit this code to github repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For some reason python function doesn't work.   \n",
    "#Need Service \n",
    "!az login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Service Account Login\n",
    "\n",
    "TBD: Need someone to research loging in with service account. The way google works you can download a json file that can be used for authentication.  This is better for eventual automation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Login \n",
    "#ku.bash_command('login',cf_a) #tbd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Resource Group and Location\n",
    "Azure must have a resource group to assocate with your activities. This will make cleanup easier. We are going to call this a project to maintain consistent nameing with GC.\n",
    "\n",
    "It is OK to run this more than once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will set the create the project. \n",
    "result= ku.bash_command('create_project',cf_a)\n",
    "\n",
    "#TBD, write a test to see if State= \"Succeeded\"\n",
    "#'{\\n  \"id\": \"/subscriptions/652b3848-14d2-4276-af14-fbcd7db53805/resourceGroups/kuberlytics\",\\n  \"location\": \"eastus\",\\n  \"managedBy\": null,\\n  \"name\": \"kuberlytics\",\\n  \"properties\": {\\n    \"provisioningState\": \"Succeeded\"\\n  },\\n  \"tags\": null\\n}\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Cluster\n",
    "You are ready to go!  We are now going to tell Azure to create a Kubernetes cluster for us.  We do this with the `az acs create --orchestrator-type=kubernetes` \n",
    "\n",
    "See full documentation [here](https://docs.microsoft.com/en-us/cli/azure/acs?view=azure-cli-latest#az_acs_create).\n",
    "\n",
    "#### Key factors\n",
    "The number of nodes and the machine type are critica factors in the volume.\n",
    "\n",
    "\n",
    "[Machine Sizes](https://docs.microsoft.com/en-us/azure/cloud-services/cloud-services-sizes-specs) \n",
    "\n",
    "[Machine Sizes](https://docs.microsoft.com/en-us/azure/virtual-machines/windows/sizes-memory)\n",
    "\n",
    "Default is a Standard_D2_v2 which has 2 CPU and 7 GB Memory. \n",
    "\n",
    "For Google ~50 Students requires 2 4 CPU and 26 GB.\n",
    "\n",
    "My thought is that \n",
    "\n",
    "Standard_E4s_v3 is the way to go for Production \n",
    "(2) While for Staging go with 1 \n",
    "\n",
    "DS11 v2\t2\t14.00 GiB\t28 GiB\t~$137.64/mo\n",
    "DS12 v2\t4\t28.00 GiB\t56 GiB\t~$276.03/mo\n",
    "\n",
    "  \"error\": {\n",
    "    \"code\": \"InvalidParameter\",\n",
    "    \"message\": \"The value 'Standard_E4s_v3' of parameter 'agentProfile.vmSize' is not allowed. Allowed values are 'Standard_A0, Standard_A1, Standard_A2, Standard_A3, Standard_A4, Standard_A5, Standard_A6, Standard_A7, Standard_A8, Standard_A9, Standard_A10, Standard_A11, Standard_D1, Standard_D2, Standard_D3, Standard_D4, Standard_D11, Standard_D12, Standard_D13, Standard_D14, Standard_D1_v2, Standard_D2_v2, Standard_D2_v2_Promo, Standard_D3_v2, Standard_D3_v2_Promo, Standard_D4_v2, Standard_D4_v2_Promo, Standard_D5_v2, Standard_D5_v2_Promo, Standard_D11_v2_Promo, Standard_DS11_v2, Standard_D12_v2, Standard_D12_v2_Promo, Standard_D13_v2, Standard_D13_v2_Promo, Standard_D14_v2, Standard_D14_v2_Promo, Standard_D15_v2, Standard_G1, Standard_G2, Standard_G3, Standard_G4, Standard_G5, Standard_A1_v2, Standard_A2_v2, Standard_A2m_v2, Standard_A4_v2, Standard_A4m_v2, Standard_A8_v2, Standard_A8m_v2, Standard_D15_v2, Standard_F1, Standard_F16, Standard_F2, Standard_F4, Standard_F8, Standard_H16, Standard_H16m, Standard_H16mr, Standard_H16r, Standard_H8, Standard_H8m, Standard_L16s, Standard_L32s, Standard_L4s, Standard_L8s, Standard_DS1, Standard_DS2, Standard_DS3, Standard_DS4, Standard_DS11, Standard_DS12, Standard_DS13, Standard_DS14, Standard_GS1, Standard_GS2, Standard_GS3, Standard_GS4, Standard_GS5, Standard_DS1_v2, Standard_DS2_v2, Standard_DS3_v2, Standard_DS4_v2, Standard_DS5_v2, Standard_DS11_v2, Standard_DS12_v2, Standard_DS13_v2, Standard_DS14_v2, Standard_DS15_v2, Standard_DS2_v2_Promo, Standard_DS3_v2_Promo, Standard_DS4_v2_Promo, Standard_DS5_v2_Promo, Standard_F16s, Standard_F1s, Standard_F2s, Standard_F4s, Standard_F8s, Standard_NC12, Standard_NC24, Standard_NC24r, Standard_NC6, Standard_NV12, Standard_NV24, Standard_NV6'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will create the cluseter\n",
    "#This should be run in a terminal because it is very long running. \n",
    "#However, it did work \n",
    "#print(cf_a['create_cluster'])\n",
    "print(ku.bash_command('create_cluster_acs',cf_a))\n",
    "\n",
    "#TBD WRITE TEST TO SEE IF \"provisioningState\": \"Succeeded\","
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying the Servers\n",
    "We can now verify that the cluster has successfully launched by asking gcloud to list the instances. This should report the number of instances specified in the num_nodes variable. \n",
    "\n",
    "`!gcloud compute instances list`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "servers=ku.bash_command('describe_cluster_acs',cf_a)\n",
    "print(servers)\n",
    "#TBD Need to parse this and just print out number of servers, size, not key. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Credentials for Kubectl\n",
    "We need to add the credentials for Kubectl to work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gcloud container clusters get-credentials kuberlytics\n",
    "print(ku.bash_command('get_credentials_acs',cf_a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check to see if we have Kubectl working. \n",
    "print(ku.bash_command(\"kubectl cluster-info\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ku.bash_command(\"kubectl get node\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ku.bash_command(\"kubectl get pods --all-namespaces\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helm Installation.  \n",
    "We are going to be utilizing Helm for  installations of a variety of analytics tools.  This command will install Tiller on your cluster.  As they say, \"Happy Helming!\" \n",
    "\n",
    "A critical factor for Helm is that you have the same version running locally and via your machine.  If you run helm version and you have the right version, then you should be fine.\n",
    "\n",
    "To install the appropriate version, \n",
    "\n",
    "```\n",
    "curl https://raw.githubusercontent.com/kubernetes/helm/master/scripts/get > get_helm.sh\n",
    "chmod 700 get_helm.sh\n",
    "RUN get_helm.sh --version v2.6.2\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ku.bash_command(\"helm version\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provided helm is installed, this will install Tiller on the Cluster.\n",
    "#If the client and the server are not the same version, do an upgrade\n",
    "#ACS already configured. \n",
    "print(ku.bash_command(\"helm init --client-only\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enabling Autoscaling (optional)\n",
    "\n",
    "This should launch a pod within your kubernetes cluster that will handle autoscaling of the cluster. Note that this seems to take a while and may even timeout. Consider opening and running in a terminal session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Currently Not possible with azure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed IP Address (optional)\n",
    "Often it can be useful to utilize a fixed IP address in order to point a DNS to an applicaiton. \n",
    "\n",
    "[1] global\n",
    " [2] region: asia-east1\n",
    " [3] region: asia-northeast1\n",
    " [4] region: asia-southeast1\n",
    " [5] region: europe-west1\n",
    " [6] region: us-central1\n",
    " [7] region: us-east1\n",
    " [8] region: us-east4\n",
    " [9] region: us-west1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reserve a fixed IP (note: you can only do this once.)\n",
    "#print(ku.bash_command(cf_g['create_fixedip']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fixed_ip=ku.get_fixed_ip(cf_g)\n",
    "#print(fixed_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Write the public IP to the Jupyterhub file.\n",
    "#jupyterhub_yaml='../../config/jupyterhub/config.yaml'\n",
    "#with open(jupyterhub_yaml, 'r') as j_yaml:\n",
    "#    cf_j=ruamel.yaml.round_trip_load(j_yaml, preserve_quotes=True)\n",
    "#cf_j['fixed_ip']=fixed_ip\n",
    "#ruamel.yaml.round_trip_dump(cf_j, open(jupyterhub_yaml, 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kubernetes Web Dashboard\n",
    "The kubernetes web dashboard can be utilized to launch applications. \n",
    "\n",
    "You the user for the dashboard is `admin` and the password can be found using the commands below. Just go ahead to the kubernetes dashbaord now. It is a great place to see the usage of your cluster and other things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can use this to show the Kubernetes Dashboard.\n",
    "result=ku.bash_command(\"kubectl cluster-info\")\n",
    "print(result)\n",
    "result=ku.bash_command('describe_cluster',cf_a)\n",
    "#result=result.split(\"\\n\")\n",
    "#password=[x for x in result if \"password:\" in x]\n",
    "#print (password)\n",
    "\n",
    "#TBD How do you get the Password for azure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl cluster-info dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### That is it! You now have your own Kubernetes cluster that is ready to go. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resize a Cluster\n",
    "To stop a cluster without deleting it you just resize it to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TBD\n",
    "ku.bash_command(cf_a['class_size_cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TBD\n",
    "#ku.bash_command(cf_g['stop_cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TBD\n",
    "ku.bash_command(cf_a['normal_size_cluster'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting a Kubernetes Cluster\n",
    "\n",
    "# **WARNING: DELETE JUPYTERHUB INSTANCE FIRST \n",
    "Should really put that in the codebase.  If you don't delete the jupyterhub instance and you are using a fixed IP the forwarding rules for the fixed-ip won't be deleted.\n",
    "\n",
    "This will delete the Kubernetes cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Always delete the namespace first. \n",
    "print(ku.bash_command('delete_project',cf_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting Fixed IP Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ku.bash_command('delete_fixedip',cf_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(ku.bash_command('describe_fixedip',cf_g))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
